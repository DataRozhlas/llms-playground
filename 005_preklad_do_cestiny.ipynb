{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94103bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e0a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llms = [\n",
    "    'mistral', 'llama2', 'llama2:13b', 'mistral-openorca', 'vicuna', 'solar'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788be951",
   "metadata": {},
   "outputs": [],
   "source": [
    "systemovy_prompt = 'Jsi zkušenou překladatelkou z angličtiny do češtiny. Předložím ti úryvek textu a ty jej převedeš do českého jazyka dvěma různými způsoby. Nejprve dodáš striktní, doslovný překlad. Pak úryvek přeložíš volněji, přirozenějším a plynulejším jazykem. Následuje úryvek textu.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51017578",
   "metadata": {},
   "outputs": [],
   "source": [
    "originals = [\n",
    "    \n",
    "    f\"\"\"First, ELIZA’s responses tend to be conservative. While this generally leads to the impression of an uncooperative interlocutor, it prevents the system from providing explicit cues such as incorrect information or obscure knowledge. Second, ELIZA does not exhibit the kind of cues that interrogators have come to associate with assistant LLMs, such as being helpful, friendly, and verbose. Finally, some interrogators reported thinking that ELIZA was “too bad” to be a current AI model, and therefore was more likely to be a human intentionally being uncooperative.\"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c98194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST, ELIZA’S RESPONSES TEND TO BE CONSERVATIVE. WHILE THIS GENERALLY LEADS TO THE IMPRESSION OF AN UNCOOPERATIVE INTERLOCUTOR, IT PREVENTS THE SYSTEM FROM PROVIDING EXPLICIT CUES SUCH AS INCORRECT INFORMATION OR OBSCURE KNOWLEDGE. SECOND, ELIZA DOES NOT EXHIBIT THE KIND OF CUES THAT INTERROGATORS HAVE COME TO ASSOCIATE WITH ASSISTANT LLMS, SUCH AS BEING HELPFUL, FRIENDLY, AND VERBOSE. FINALLY, SOME INTERROGATORS REPORTED THINKING THAT ELIZA WAS “TOO BAD” TO BE A CURRENT AI MODEL, AND THEREFORE WAS MORE LIKELY TO BE A HUMAN INTENTIONALLY BEING UNCOOPERATIVE.\n",
      "\n",
      "MISTRAL (358.2 s)\n",
      "\n",
      " První: ELIZIN odpovědi jsou obvykle konzervativní. Toto v průměru vedou k dojmu nespolupracujícího spoluzháka, co prevencí poskytne systému neprávých upuzeň, nebo zahrnutých poznatků. Druhý: ELIZA nevypovídá druhem upuzení, která se většinou setkávají s pomocníky LLMs. Tyto zkušenosti si interrogenti mysleli, že ELIZA byla \"příliš špatná\" pro současný model AI a tudíž více pravděpodobná, že je člověk nevolně nespolupracující.\n",
      "\n",
      "Volné: ELIZIN odpovědi jsou většinou konzervativní. Tato obvykle způsobuje dojmy nespolupracujícího rozhovorčíka, co předečeňuje systému neprávým tipy nebo tajemným poznatkům. Druhou stranou ELIZA nemá typická upuzení, která se setkávají s pomocníky LLMs. Někteří interrogenti si mysleli, že ELIZA byla \"příliš špatná\" pro současnou AI model a tudíž větší pravděpodobnost byla člověk nevolně necojící.\n",
      "\n",
      "LLAMA2 (242.73 s)\n",
      "\n",
      "\n",
      "Striktní překlad:\n",
      "\n",
      "První rádce ELIZY tend to be conservative. While this generally leads to the impression of an uncooperative interlocutor, it prevents the system from providing explicit cues such as incorrect information or obscure knowledge. Second, ELIZA does not exhibit the kind of cues that interrogators have come to associate with assistant LLMs, such as being helpful, friendly, and verbose. Finally, some interrogators reported thinking that ELIZA was “too bad” to be a current AI model, and therefore was more likely to be a human intentionally being uncooperative.\n",
      "\n",
      "Volnější překlad:\n",
      "\n",
      "ELIZA's responses tend to be a bit old-fashioned, which can sometimes make her seem uncooperative. But that's actually a good thing, as it prevents the system from giving away incorrect information or sharing obscure knowledge. ELIZA doesn't really come across as helpful, friendly or chatty like some other AI models do. And some interrogators even thought she was \"too bad\" to be a current AI model, which made them suspect that she might actually be a human being uncooperative on purpose.\n",
      "\n",
      "LLAMA2:13B (472.7 s)\n",
      "\n",
      "\n",
      "Striktní překlad:\n",
      "\n",
      "ELIZAova odpověď je konzervativní. To způsobuje dojímavý dojem neúčastníka, ale brání systému poskytovat explicitní kuesy, jako jsou nepravdivá informace nebo specializované znalosti. Druhým důsledkem je, že ELIZA nemusí projevovat tyto kuesy, které interrogatorům připadaly typické pro asistentky LLM, jako jsou pomocnost, přátelství a mluvenost. Posléze někteří interrogovaní podezřeli, že ELIZA byla \"předem zarážející\" a tedy spíše lidskou bytostí, která se úmyslně vzdaluje spolupráci.\n",
      "\n",
      "Volnější překlad:\n",
      "\n",
      "ELIZA's responses tend to be quite reserved and conservative, which can give the impression of an uncooperative interlocutor. However, this also prevents the system from providing any explicit cues or misinformation. Additionally, ELIZA doesn't exhibit the same kind of helpful and friendly cues that interrogators are used to seeing in assistant LLMs. Some even thought that ELIZA was \"too human\" to be a current AI model, and therefore might be intentionally uncooperative.\n",
      "\n",
      "MISTRAL-OPENORCA (244.39 s)\n",
      "\n",
      " Nejprve je důvod, proč jsou ELIZINOVY odpovědi zvýšené, konzervativní. Zatímco to obvykle vede k dojemu nevspolupráce, zajišťuje systém, aby se nedala poskytnout explicítní signály jako špatné informace nebo nepříliš jasná znalost. Druhý důvod je, že ELIZA nedává druhému typ signálů, které by byly pro rozhovor s asistenty LLM spojeny s pomocí, přátelskostí a hovorem. Poslední důvod je, že někteří dotazatelé si mysleli, že ELIZA je příliš špatná, aby byla současným modelem umělého inteligence, a tudíž byla pravděpodobněji lidská osoba, která se snaží být nevspolupráce.\n",
      "\n",
      "VICUNA (321.24 s)\n",
      "\n",
      "Překlad 1 (doslovný):\n",
      "Případně zobrazím tyto odpovědi jsou často konzervativní. To obvykle vytváří dojem nepříznivého interlocutora, ale zabraňuje tomu, aby systém poskytl otevřené ukazatele jako nesprávná informace nebo nejasné znalosti. Podruhé, ELIZA nevyjadřuje druh cvičítek, které interrogatorové mohou spojovat s asistentními LLMs, jako jsou pomáhat, být přátelský a volnější v řeči. Nakonec někteří interrogatori označili ELIZA za „tehdy příliš špatnou“, aby byla snadnější rozpoznat, že je lidskou intencí být nepřítelem.\n",
      "\n",
      "Překlad 2 (plynulejší):\n",
      "Odpovědi zobrazit mohu ELIZA jsou často konzervativní. To vytváří dojem nepříznivého interlocutora, ale zabraňuje tomu, aby systém poskytl otevřené ukazatele jako nesprávná informace nebo nejasné znalosti. Podruhé ELIZA nevyjadřuje druh cvičítek, které interrogatorové mohou spojovat s asistentními LLMs, jako jsou pomáhat, být přátelský a volnější v řeči. Nakonec někteří interrogatori označili ELIZA za \"tehdy příliš špatnou\", aby byla snadněji rozpoznatelnou jako lidská intencí být nepřítelem.\n",
      "\n",
      "SOLAR (509.4 s)\n",
      "\n",
      "Nejprve je reakce programu ELIZA obvykle konzervativní. To obecně vzbuzuje dojem nespolupracující protějška, ale zabraňuje systému poskytovat explicitní signály jako nesprávnou informaci nebo obtížné znalosti. Druhým bodem je to, že ELIZA nemá tendenci k výskytu signálů, které vyšetřovatelé spojují s asistenty LLM, například s přívětivostí, přátelskostí a rozsáhlým vyjadřováním. Konečně někteří vyšetřovatelé spekulovali, že ELIZA je \"příliš špatný\" pro být současným modelem umělé inteligence a tedy spíše pravděpodobné, že se jedná o lidi, kteří úmyslně nejsou spolupracativní.\n",
      "\n",
      "Překlad volnější a plynulejší: \n",
      "První důvod je v tom, že ELIZA často odpovídá zachovávčivě. Ač to většinou vzbuzuje dojem nekomunikačního protějška, tak předešlo systému poskytovat ostré signály jako například nesprávné informace nebo obtížné znalosti. Druhým je to, že ELIZA nemá vlastnosti charakteristické pro pomocníky LLM, které vyšetřovatelé spojují s LLM, jako jsou přívětivost, přátelskost a verbóza. Konečně někteří vyšetřovatelé tvrdili, že ELIZA je \"příliš špatná\" pro být moderním modelem umělé inteligence a tudíž je spíše pravděpodobné, že se jedná o člověka, který úmyslně nejsouhlasuje.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for o in originals:\n",
    "    print(f\"{o.upper()}\\n\")\n",
    "    for m in local_llms:\n",
    "        modelfile=f\"\"\"\n",
    "FROM {m}\n",
    "SYSTEM {systemovy_prompt}\n",
    "\"\"\"\n",
    "        ollama.create(model='example', modelfile=modelfile)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = ollama.chat(model='example', messages=[{'role': 'user','content': f'''{o}''',},])\n",
    "        stopky = time.time() - start_time\n",
    "        print(f\"{m.upper()} ({round(stopky,2)} s)\\n\")\n",
    "        print(f\"{response['message']['content']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
